{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from scipy.stats import mode\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Preprocess And Scalling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset paths\n",
    "dataset_path_healthy = \"../../split_fif/healthy_csv\"\n",
    "dataset_path_mdd = \"../../split_fif/mdd_csv\"\n",
    "dataset_path_other = \"../../split_fif/other_csv\"\n",
    "\n",
    "def load_and_preprocess(directory, label=None):\n",
    "    \"\"\" Load and preprocess dataset \"\"\"\n",
    "    data_frames = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(directory, file))\n",
    "            if label is not None:\n",
    "                df[\"Label\"] = label\n",
    "            data_frames.append(df)\n",
    "    df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "# Load and merge datasets\n",
    "df_healthy = load_and_preprocess(dataset_path_healthy, label=0)\n",
    "df_mdd = load_and_preprocess(dataset_path_mdd, label=1)\n",
    "df_other = load_and_preprocess(dataset_path_other, label=2)\n",
    "\n",
    "df = pd.concat([df_healthy, df_mdd, df_other], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop(columns=['Label']).values\n",
    "y = df['Label'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler(feature_range=(0, 100))\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp)\n",
    "\n",
    "X_train_gpu = cp.array(X_train)\n",
    "y_train_gpu = cp.array(y_train)\n",
    "\n",
    "\n",
    "joblib.dump(scaler, \"multi_class_best_scaler.pkl\")\n",
    "\n",
    "# ---- Train Models with Optimized Hyperparameters ---- #\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Ensure missing values are handled\n",
    "imputer = SimpleImputer(strategy=\"median\")  # Replace NaN with median value\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_val = imputer.transform(X_val)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Save imputer for future predictions\n",
    "joblib.dump(imputer, \"multi_class_imputer.pkl\")\n",
    "\n",
    "# Reapply MinMax Scaling (in case imputer changed values)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized XGBoost Model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    learning_rate=0.01,  # Prevent overfitting\n",
    "    max_depth=15,  # Balanced depth\n",
    "    gamma=0.2,\n",
    "    subsample=0.9,  # Avoid overfitting\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=3,  # Prevent overfitting\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=2.0,\n",
    "    n_estimators=3000,  # Reduce to prevent overfitting\n",
    "    verbosity=1,\n",
    "    num_class=3\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
    "\n",
    "# Optimized Random Forest Model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,  # Sufficient trees for stability\n",
    "    max_depth=20,  # Avoid overfitting\n",
    "    min_samples_split=5,  # Avoid too many splits\n",
    "    min_samples_leaf=2,  # Prevent deep trees\n",
    "    max_features=\"sqrt\",  # Balance feature selection\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "joblib.dump(rf_model, \"rf_model.pkl\")\n",
    "\n",
    "# Optimized Support Vector Machine (SVM)\n",
    "svm_model = SVC(\n",
    "    C=1.5,  # Regularization to prevent overfitting\n",
    "    kernel=\"rbf\",  # Best for non-linear problems\n",
    "    gamma=\"scale\",  # Auto-tuned gamma\n",
    "    probability=True,  # Needed for predict_proba()\n",
    "    random_state=42\n",
    ")\n",
    "svm_model.fit(X_train, y_train)\n",
    "joblib.dump(svm_model, \"svm_model.pkl\")\n",
    "\n",
    "# Optimized Logistic Regression\n",
    "log_reg = LogisticRegression(\n",
    "    C=1.0,  # Standard regularization\n",
    "    solver=\"lbfgs\",  # Handles multi-class well\n",
    "    max_iter=500,  # Ensure convergence\n",
    "    random_state=42\n",
    ")\n",
    "log_reg.fit(X_train, y_train)\n",
    "joblib.dump(log_reg, \"log_reg.pkl\")\n",
    "\n",
    "# Load models for ensemble\n",
    "models = {\n",
    "    \"XGBoost\": xgb_model,\n",
    "    \"RandomForest\": rf_model,\n",
    "    \"SVM\": svm_model,\n",
    "    \"LogisticRegression\": log_reg\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8108\n",
      "RandomForest Accuracy: 0.8649\n",
      "SVM Accuracy: 0.7838\n",
      "LogisticRegression Accuracy: 0.8649\n",
      "\n",
      "Best Model: RandomForest with Accuracy: 0.8649\n",
      "\n",
      "Ensemble Model Accuracy: 0.8649\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "model_accuracies = {}\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    model_accuracies[name] = accuracy\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "best_model_name = max(model_accuracies, key=model_accuracies.get)\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nBest Model: {best_model_name} with Accuracy: {model_accuracies[best_model_name]:.4f}\")\n",
    "\n",
    "# Ensemble Learning - Soft Voting\n",
    "val_preds_prob = np.zeros((X_val.shape[0], len(models)))\n",
    "\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    val_preds_prob[:, idx] = np.argmax(model.predict_proba(X_val), axis=1)\n",
    "\n",
    "ensemble_preds = mode(val_preds_prob, axis=1)[0].flatten()\n",
    "ensemble_accuracy = accuracy_score(y_val, ensemble_preds)\n",
    "print(f\"\\nEnsemble Model Accuracy: {ensemble_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Predict Using Ensemble\n",
    "def predict_class(X_predict_scaled):\n",
    "    model_probs = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            prob = model.predict_proba(X_predict_scaled)[0]\n",
    "            model_probs[name] = prob\n",
    "        except AttributeError:\n",
    "            print(f\"Model {name} does not support probability prediction.\")\n",
    "\n",
    "    # Averaging Probabilities (Soft Voting)\n",
    "    avg_probs = np.mean(list(model_probs.values()), axis=0)\n",
    "\n",
    "    # Get final prediction\n",
    "    final_class = np.argmax(avg_probs)\n",
    "\n",
    "    # Print Probabilities\n",
    "    class_probabilities = {f\"Class {i}\": avg_probs[i] * 100 for i in range(len(avg_probs))}\n",
    "\n",
    "    print(f\"\\nFinal Prediction: Class {final_class}\")\n",
    "    for cls, prob in class_probabilities.items():\n",
    "        print(f\"{cls}: {prob:.2f}%\")\n",
    "\n",
    "    return final_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Prediction: Class 1\n",
      "Class 0: 12.92%\n",
      "Class 1: 83.99%\n",
      "Class 2: 3.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Usage:\n",
    "X_predict_scaled = scaler.transform(X_test[:-1])  # Test with one sample\n",
    "predict_class(X_predict_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
