{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np \n",
    "import mne\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from mne.preprocessing import ICA\n",
    "from mne.time_frequency import psd_array_welch\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "import pywt  # For wavelet transform\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eeg_data(vhdr_file_path, l_freq=1.0, h_freq=40.0, notch_freq=50):\n",
    "    \"\"\"Preprocess EEG data.\"\"\"\n",
    "    raw = mne.io.read_raw_brainvision(vhdr_file_path, preload=True)\n",
    "    \n",
    "    # Set EOG channels\n",
    "    eog_channels = ['VPVA', 'VNVB', 'HPHL', 'HNHR']\n",
    "    raw.set_channel_types({ch: 'eog' for ch in eog_channels if ch in raw.ch_names})\n",
    "    \n",
    "    # Apply notch filter and bandpass filter\n",
    "    raw.notch_filter(freqs=[notch_freq], picks='eeg')\n",
    "    raw.filter(l_freq=l_freq, h_freq=h_freq, picks='eeg')\n",
    "    \n",
    "    # Set EEG reference to average\n",
    "    raw.set_eeg_reference('average', projection=True)\n",
    "    \n",
    "    # ICA for artifact removal\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)\n",
    "    ica.fit(raw)\n",
    "    eog_indices, _ = ica.find_bads_eog(raw)\n",
    "    ica.exclude = eog_indices\n",
    "    raw = ica.apply(raw)\n",
    "    \n",
    "    # Drop specific channels after ICA\n",
    "    channels_to_drop = ['Erbs', 'OrbOcc', 'Mass']\n",
    "    raw.drop_channels([ch for ch in channels_to_drop if ch in raw.ch_names])\n",
    "    \n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_and_save_eeg(vhdr_file_path,output_dir,slice_duration=60):\n",
    "    \"\"\"Preprocess, slice, and save EEG data into 60-second segments.\"\"\"\n",
    "    \n",
    "    # Extract the base name for saving\n",
    "    base_name = os.path.splitext(os.path.basename(vhdr_file_path))[0]\n",
    "    \n",
    "    # Perform preprocessing\n",
    "    raw = preprocess_eeg_data(vhdr_file_path)\n",
    "    \n",
    "    # Calculate the number of samples per slice\n",
    "    samples_per_slice = int(slice_duration * raw.info['sfreq'])\n",
    "    \n",
    "    # Calculate the number of slices\n",
    "    num_slices = int(len(raw) / samples_per_slice)\n",
    "    \n",
    "    # Slice and save\n",
    "    for i in range(num_slices):\n",
    "        start_sample = i * samples_per_slice\n",
    "        end_sample = (i + 1) * samples_per_slice\n",
    "        \n",
    "        # Create a new raw object for the slice\n",
    "        sliced_raw = raw.copy().crop(tmin=start_sample / raw.info['sfreq'], tmax=end_sample / raw.info['sfreq'], include_tmax=False)\n",
    "        \n",
    "        # Construct the filename for the slice\n",
    "        slice_filename = f\"{base_name}_{i + 1}.fif\"\n",
    "        \n",
    "        # Save the slice in the output directory\n",
    "        slice_output_path = os.path.join(output_dir, slice_filename)\n",
    "        sliced_raw.save(slice_output_path, overwrite=True)\n",
    "        print(f\"Slice {i + 1} saved as: {slice_output_path}\")\n",
    "\n",
    "    # Handle the remaining data (if any)\n",
    "    remaining_samples = len(raw) - (num_slices * samples_per_slice)\n",
    "    if remaining_samples > 0:\n",
    "        start_sample = num_slices * samples_per_slice\n",
    "        remaining_raw = raw.copy().crop(tmin=start_sample / raw.info['sfreq'])\n",
    "        remaining_filename = f\"{base_name}_2.fif\"\n",
    "        # Save the remaining data in the output directory\n",
    "        remaining_output_path = os.path.join(output_dir, remaining_filename)\n",
    "        remaining_raw.save(remaining_output_path, overwrite=True)\n",
    "        print(f\"Remaining data saved as: {remaining_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_and_save_eeg(\"dataset_s/mdd/sub-88000489/ses-1/eeg/sub-88000489_ses-1_task-restEC_eeg.vhdr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_folder(source_folder, destination_folder):\n",
    "    \"\"\"\n",
    "    Processes EO files for all subjects and sessions, saving the features to CSV files.\n",
    "\n",
    "    Args:\n",
    "        source_folder (str): Path to the root folder containing subject EEG files.\n",
    "        destination_folder (str): Path to the folder where CSV files will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    for sub_id in os.listdir(source_folder):\n",
    "        subject_path = os.path.join(source_folder, sub_id)\n",
    "        if not os.path.isdir(subject_path):\n",
    "            continue\n",
    "        \n",
    "        for ses_id in os.listdir(subject_path):\n",
    "            session_path = os.path.join(subject_path, ses_id, \"eeg\")\n",
    "            if not os.path.isdir(session_path):\n",
    "                continue\n",
    "            \n",
    "            for file in os.listdir(session_path):\n",
    "                if file.endswith(\"_eeg.vhdr\"):\n",
    "                    inp_path = os.path.join(session_path, file)\n",
    "                    output_filename = f\"{file.replace('.vhdr', '.fif')}\"\n",
    "                    # output_filename = output_filename.replace(\"task-restcombined\", \"task-rest_combined\")\n",
    "                    output_path = os.path.join(destination_folder, output_filename)\n",
    "                    slice_and_save_eeg(inp_path,destination_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_folder(\"dataset_s/mdd\",\"split_fif/mdd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channel_features(raw, fmin=0.5, fmax=50):\n",
    "    # Select only EEG channels\n",
    "    raw.pick_types(eeg=True)  # This removes non-EEG channels\n",
    "    data = raw.get_data()\n",
    "    channel_names = raw.ch_names\n",
    "    features = {ch: {} for ch in channel_names}\n",
    "\n",
    "    # Time-domain features\n",
    "    for i, ch in enumerate(channel_names):\n",
    "        features[ch]['mean'] = np.mean(data[i])\n",
    "        features[ch]['variance'] = np.var(data[i])\n",
    "        features[ch]['skewness'] = skew(data[i])\n",
    "        features[ch]['kurtosis'] = kurtosis(data[i])\n",
    "        features[ch]['peak_to_peak'] = np.ptp(data[i])\n",
    "\n",
    "        # Fourier Transform (FFT)\n",
    "        fft_values = np.abs(fft(data[i]))\n",
    "        features[ch]['fft_mean'] = np.mean(fft_values)\n",
    "        features[ch]['fft_std'] = np.std(fft_values)\n",
    "        features[ch]['fft_max'] = np.max(fft_values)\n",
    "        \n",
    "        # Wavelet Transform (Morlet)\n",
    "        wavelet = 'cmor1.5-1.0'\n",
    "        coeffs, _ = pywt.cwt(data[i], scales=np.arange(1, 129), wavelet=wavelet)\n",
    "        coeffs = np.abs(coeffs)  # Convert complex values to magnitude\n",
    "        \n",
    "        features[ch]['wavelet_energy'] = np.sum(np.square(coeffs))\n",
    "\n",
    "        # Wavelet Transform (DWT) using Daubechies wavelet (db4) #morle\n",
    "        # coeffs = pywt.wavedec(data[i], 'db4', level=4)\n",
    "        # features[ch]['wavelet_energy'] = sum(np.sum(np.square(c)) for c in coeffs)\n",
    "        \n",
    "        # features[ch]['wavelet_entropy'] = 0  # Initialize wavelet_entropy\n",
    "        \n",
    "        # for c in coeffs:\n",
    "        #     c = c[np.isfinite(c)]\n",
    "        #     c_norm = c / (np.sum(np.abs(c)) + 1e-10)\n",
    "        #     features[ch]['wavelet_entropy'] += -np.sum(c_norm * np.log2(c_norm + 1e-10))\n",
    "\n",
    "    # Frequency-domain features using PSD\n",
    "    psd = raw.compute_psd(method='welch', fmin=fmin, fmax=fmax, n_fft=2048)\n",
    "    psd_data = psd.get_data()\n",
    "    freqs = psd.freqs\n",
    "    psd_df = pd.DataFrame(psd_data, columns=freqs, index=channel_names)\n",
    "\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'slow_alpha': (6, 9), 'alpha': (8, 12),\n",
    "             'beta': (12, 30), 'gamma': (30, 50)}\n",
    "\n",
    "    for band, (low, high) in bands.items():\n",
    "        band_power = psd_df.loc[:, (freqs >= low) & (freqs <= high)].mean(axis=1)\n",
    "        for ch in channel_names:\n",
    "            features[ch][f'{band}_power'] = band_power[ch]\n",
    "\n",
    "    # Frontal Alpha Asymmetry (F3-F4)\n",
    "    if 'F3' in channel_names and 'F4' in channel_names:\n",
    "        features['F3_F4_alpha_asymmetry'] = features['F4']['alpha_power'] - features['F3']['alpha_power']\n",
    "\n",
    "    # Convert features to DataFrame\n",
    "    features_df = pd.DataFrame(features).T\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_combine(eo_file_path, ec_file_path, output_file):\n",
    "    all_features = []\n",
    "\n",
    "    # Process EO file\n",
    "    raw_eo = mne.io.read_raw_fif(eo_file_path)\n",
    "    features_eo = extract_channel_features(raw_eo)\n",
    "    features_eo['condition'] = 'EO'\n",
    "    all_features.append(features_eo)\n",
    "\n",
    "    # Process EC file\n",
    "    raw_ec = mne.io.read_raw_fif(ec_file_path)\n",
    "    features_ec = extract_channel_features(raw_ec)\n",
    "    features_ec['condition'] = 'EC'\n",
    "    all_features.append(features_ec)\n",
    "\n",
    "    # Combine EO and EC features\n",
    "    combined_features = pd.concat(all_features, keys=['EO', 'EC'], names=['condition', 'channel'])\n",
    "    \n",
    "    # Save combined features to a single CSV file\n",
    "    combined_features.to_csv(output_file)\n",
    "    print(f\"Features successfully saved to {output_file}\")\n",
    "    # return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_combine(\"split_fif/mdd/sub-88000489_ses-1_task-restEC_eeg_1.fif\",\"split_fif/mdd/sub-88000489_ses-1_task-restEC_eeg_1.fif\",\"split_fif/mdd/sub-88000489_ses-1_task-restEC_eeg_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_folder(source_folder, destination_folder):\n",
    "    \"\"\"\n",
    "    Processes EO files for all subjects and sessions, saving the features to CSV files.\n",
    "\n",
    "    Args:\n",
    "        source_folder (str): Path to the root folder containing subject EEG files.\n",
    "        destination_folder (str): Path to the folder where CSV files will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    output_filename=\"\"\n",
    "    eo_path=\"\"\n",
    "    ec_path=\"\"\n",
    "    print(os.listdir(source_folder))\n",
    "    for sub_id in os.listdir(source_folder):\n",
    "        subject_path = os.path.join(source_folder, sub_id)\n",
    "        if not os.path.isdir(subject_path):\n",
    "            continue\n",
    "        \n",
    "        for ses_id in os.listdir(subject_path):\n",
    "            session_path = os.path.join(subject_path, ses_id, \"eeg\")\n",
    "            if not os.path.isdir(session_path):\n",
    "                continue\n",
    "            print(ses_id)\n",
    "            for file in os.listdir(session_path):\n",
    "                if file.endswith(\"EC_eeg_1.fif\") or file.endswith(\"EC_eeg_2.fif\"):\n",
    "                    eo_path = os.path.join(session_path, file)\n",
    "                elif file.endswith(\"EO_eeg_1.fif\") or file.endswith(\"EO_eeg_2.fif\"):\n",
    "                    ec_file=file\n",
    "                    ec_path = os.path.join(session_path, file)\n",
    "                \n",
    "                print(eo_path,ec_path)\n",
    "                output_filename=ec_file.replace(\"EC_eeg\",\"_eeg_combined.csv\")\n",
    "                process_and_combine(eo_path,ec_path,output_filename)\n",
    "\n",
    "                \n",
    "                \n",
    "                # output_path = os.path.join(destination_folder, output_filename)\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_folder(source_folder, destination_folder):\n",
    "    \"\"\"\n",
    "    Processes EO and EC files for all subjects and sessions, saving the features to CSV files.\n",
    "\n",
    "    Args:\n",
    "        source_folder (str): Path to the root folder containing subject EEG files.\n",
    "        destination_folder (str): Path to the folder where CSV files will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    eo_path, ec_path = None, None\n",
    "    ec_file = None  # Initialize ec_file to avoid the UnboundLocalError\n",
    "\n",
    "    # Iterate through files in the source folder\n",
    "    for file in os.listdir(source_folder):\n",
    "        file_path = os.path.join(source_folder, file)\n",
    "\n",
    "        if file.endswith(\"EC_eeg_1.fif\") or file.endswith(\"EC_eeg_2.fif\"):\n",
    "            ec_path = file_path\n",
    "            ec_file = file  # Store EC file name for output filename generation\n",
    "        elif file.endswith(\"EO_eeg_1.fif\") or file.endswith(\"EO_eeg_2.fif\"):\n",
    "            eo_path = file_path\n",
    "\n",
    "        # Process only when both EO and EC files are found\n",
    "        if eo_path and ec_path and ec_file:\n",
    "            output_filename = ec_file.replace(\"EC_eeg\", \"eeg_combined.csv\")\n",
    "            output_filepath = os.path.join(destination_folder, output_filename)\n",
    "\n",
    "            print(f\"Processing: \\n  EO: {eo_path} \\n  EC: {ec_path} \\n  Output: {output_filepath}\")\n",
    "            process_and_combine(eo_path, ec_path, output_filepath)\n",
    "\n",
    "            # Reset paths after processing\n",
    "            eo_path, ec_path, ec_file = None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_folder(\"dataset_s/mdd\",\"split_fif/mdd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
