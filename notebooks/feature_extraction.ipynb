{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from scipy import signal\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.stats import skew, kurtosis\n",
    "import os\n",
    "import bisect\n",
    "\n",
    "mne.set_cache_dir('/tmp/shm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the participant metadata\n",
    "participants_df = pd.read_csv(\"TDBRAIN_participants_V2_cleaned.tsv\", sep=\"\\t\")\n",
    "bin_edges = [0, 6, 13, 18, 26, 41, 61]      # left edges\n",
    "labels =    [0, 6, 13, 18, 26, 41, 61]\n",
    "\n",
    "\n",
    "def get_gender(subject_id):\n",
    "    \"\"\"\n",
    "    Get gender from the participants TSV file.\n",
    "    Returns: 1 (Male), 0 (Female), -1 (Unknown)\n",
    "    \"\"\"\n",
    "    row = participants_df.loc[participants_df[\"participants_ID\"] == subject_id]\n",
    "    if not row.empty:\n",
    "        return int(row[\"gender\"].values[0])  # Convert to int (0 or 1)\n",
    "    return -1  # Default if not found\n",
    "def get_age(subject_id):\n",
    "    \"\"\"\n",
    "    Get age from the participants TSV file.\n",
    "    Returns: Age in years\n",
    "    \"\"\"\n",
    "    age = 0\n",
    "    row = participants_df.loc[participants_df[\"participants_ID\"] == subject_id]\n",
    "    if not row.empty:\n",
    "        age = int(row[\"age\"].values[0])  # Convert to int\n",
    "    idx = bisect.bisect_right(bin_edges, age) - 1\n",
    "    return labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(vhdr_path, condition):\n",
    "    \"\"\"\n",
    "    Extract features from preprocessed EEG data and save to CSV\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw : mne.io.Raw\n",
    "        Preprocessed EEG data\n",
    "    condition : str\n",
    "        Condition of the EEG recording (EO or EC)\n",
    "    save_path : str, optional\n",
    "        Path to save the extracted features CSV file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame containing extracted features\n",
    "    \"\"\"\n",
    "    # Get data and sampling frequency\n",
    "    # raw = preprocess_eeg(vhdr_path)\n",
    "    raw = mne.io.read_raw_fif(vhdr_path, preload=True)\n",
    "    # raw.pick_types(eeg=True)  \n",
    "    other_channels = ['VPVA', 'VNVB', 'HPHL', 'HNHR', 'Erbs', 'OrbOcc']\n",
    "    raw.pick('eeg')  # Pick only EEG channels\n",
    "    subject_id = vhdr_path.split('/')[-1].split('_')[0]\n",
    "    # raw.drop_channels('Mass')  # Drop 'Mass' channel if it exists\n",
    "    data = raw.get_data()\n",
    "    sfreq = raw.info['sfreq']\n",
    "    ch_names = raw.ch_names\n",
    "    # print(f\"Channel names: {ch_names}\")\n",
    "    # Initialize feature dictionary\n",
    "    features = {}\n",
    "    \n",
    "    features['gender'] = get_gender(subject_id)\n",
    "    features['age'] = get_age(subject_id)\n",
    "    # features['age']=\n",
    "    \n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 13),\n",
    "        'beta': (13, 30),\n",
    "        'gamma': (30, 40)\n",
    "    }\n",
    "    \n",
    "    # Calculate features for each channel\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        # Get channel data\n",
    "        ch_data = data[i]\n",
    "        prefix = f\"{condition}_{ch.lower()}\"\n",
    "        # print(prefix)\n",
    "        # Time domain features\n",
    "        features[f'{prefix}_mean'] = np.mean(ch_data)\n",
    "        features[f'{prefix}_std'] = np.std(ch_data)\n",
    "        features[f'{prefix}_skew'] = skew(ch_data)\n",
    "        features[f'{prefix}_kurtosis'] = kurtosis(ch_data)\n",
    "        \n",
    "        # Frequency domain features\n",
    "        freqs, psd = signal.welch(ch_data, fs=sfreq, nperseg=int(sfreq*2))\n",
    "        features[f'{prefix}_psd_mean'] = np.mean(psd)\n",
    "        # Band-specific FFT features\n",
    "        fft_vals = np.abs(np.fft.fft(ch_data))\n",
    "        fft_freqs = np.fft.fftfreq(len(ch_data), d=1/sfreq)\n",
    "        \n",
    "        for band, (fmin, fmax) in bands.items():\n",
    "            idx_band = np.logical_and(fft_freqs >= fmin, fft_freqs <= fmax)\n",
    "            band_fft_vals = fft_vals[idx_band]\n",
    "            features[f'{prefix}_{band}_fft_avg_power'] = np.mean(band_fft_vals)\n",
    "        \n",
    "        # Band-specific Morlet Wavelet Transform (MWT)\n",
    "        valid_freqs = [f for f in freqs if f > 0]  # Ensure only positive frequencies\n",
    "        \n",
    "        if valid_freqs:\n",
    "            mwt = mne.time_frequency.tfr_array_morlet(\n",
    "                data[np.newaxis, [i], :], sfreq, freqs=valid_freqs, n_cycles=2, output='power'\n",
    "            ).squeeze()\n",
    "            \n",
    "            for j, f in enumerate(valid_freqs):\n",
    "                for band, (fmin, fmax) in bands.items():\n",
    "                    if fmin <= f <= fmax:\n",
    "                        features[f'{prefix}_{band}_mwt_avg_power'] = np.mean(mwt[j])\n",
    "    \n",
    "    # Convert to DataFrame and save as CSV\n",
    "    features_df = pd.DataFrame([features])\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_combine(eo_file_path, ec_file_path, output_file):\n",
    "    all_features = []\n",
    "    eo=False\n",
    "    ec=False\n",
    "    # Process EO file\n",
    "    try:       \n",
    "        features_eo = extract_features(eo_file_path,\"EO\")\n",
    "        all_features.append(features_eo)\n",
    "        eo=True\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    features_ec = extract_features(ec_file_path,\"EC\")\n",
    "    all_features.append(features_ec)\n",
    "    ec=True\n",
    "    \n",
    "    # Combine EO and EC features\n",
    "    if eo and ec:\n",
    "        combined_features = pd.concat(all_features,axis=1)\n",
    "    # print(\"*****************************\",combined_features.shape,\"***********************************\")\n",
    "    # out_path = (out_dir,output_file)\n",
    "    # Save combined features to a single CSV file\n",
    "        combined_features.to_csv(output_file,index=False)\n",
    "        print(f\"Features successfully saved to {output_file}\")\n",
    "    # return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_output_filename(file_name):\n",
    "    \"\"\"\n",
    "    Extracts base from filename and returns formatted output filename.\n",
    "    Example: 'sub-88025281_ses-1_task-restEC_eeg_1_eeg.fif' â†’\n",
    "             'sub-88025281_ses-1_task-resteeg_combined_1.csv'\n",
    "    \"\"\"\n",
    "    match = re.match(r\"(sub-[^_]+_ses-\\d+_task-rest)[A-Z]{2}_eeg_(\\d)_eeg\\.fif\", file_name)\n",
    "    if match:\n",
    "        base, slice_num = match.groups()\n",
    "        return f\"{base}eeg_combined-{slice_num}.csv\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def process_folder(source_folder, destination_folder):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    file_groups = defaultdict(dict)\n",
    "\n",
    "    for file in os.listdir(source_folder):\n",
    "        if not file.endswith(\".fif\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(source_folder, file)\n",
    "        match = re.match(r\"(sub-[^_]+)_ses-(\\d+)_task-rest(EO|EC)_eeg_(\\d)_eeg\\.fif\", file)\n",
    "        if match:\n",
    "            subject, session, condition, slice_num = match.groups()\n",
    "            key = f\"{subject}_ses-{session}_slice-{slice_num}\"\n",
    "            file_groups[key][condition] = file_path\n",
    "            file_groups[key]['raw_file'] = file  # For naming output\n",
    "\n",
    "    for key, files in sorted(file_groups.items()):  # sorted for consistent order\n",
    "        eo_path = files.get('EO')\n",
    "        ec_path = files.get('EC')\n",
    "        raw_file = files.get('raw_file')\n",
    "\n",
    "        if eo_path and ec_path and raw_file:\n",
    "            output_filename = get_output_filename(raw_file)  # already uses slice\n",
    "            output_filepath = os.path.join(destination_folder, output_filename)\n",
    "            print(f\"Processing:\\n  EO: {eo_path}\\n  EC: {ec_path}\\n  Output: {output_filepath}\")\n",
    "            process_and_combine(eo_path, ec_path, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "process_folder(\"/mnt/data/saikrishna/Team_4/split_fif_new/mdd\",\"../preprocessed_data_new/mdd\")\n",
    "print(\"After\")\n",
    "process_folder(\"/mnt/data/saikrishna/Team_4/split_fif_new/healthy\",\"../preprocessed_data_new/healthy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
