{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from mne.preprocessing import ICA\n",
    "from mne.time_frequency import psd_array_welch\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "import pywt  # For wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import fft, ifft, fftfreq\n",
    "\n",
    "def morlet_wavelet(t, f, sigma=1.0):\n",
    "    return np.exp(2j * np.pi * f * t) * np.exp(-t**2 / (2 * sigma**2))\n",
    "\n",
    "def manual_morlet_transform(data, scales, fs=1.0):\n",
    "    t = np.arange(len(data)) / fs\n",
    "    transformed = []\n",
    "    for scale in scales:\n",
    "        wavelet = morlet_wavelet(t - np.mean(t), scale)\n",
    "        wavelet /= np.linalg.norm(wavelet)  # Normalize wavelet\n",
    "        convolved = ifft(fft(data) * fft(wavelet)).real\n",
    "        transformed.append(convolved)\n",
    "    return transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channel_features(raw, condition, fmin=0.5, fmax=50):\n",
    "    # Select only EEG channels\n",
    "    raw.pick('eeg')\n",
    "    data = raw.get_data()\n",
    "    channel_names = raw.ch_names\n",
    "    features = {}  # Store condition as 0 for EO, 1 for EC\n",
    "    scales = np.linspace(2, 30, 10)  # Covers 8-30 Hz range (Alpha & Beta)\n",
    "    fs = raw.info['sfreq'] # Sampling frequency\n",
    "    # condition_prefix = 'eo' if condition == 0 else 'ec'\n",
    "    \n",
    "    # Time-domain features\n",
    "    for i, ch in enumerate(channel_names):\n",
    "        key_prefix = f'{condition}_{ch.lower()}'\n",
    "        features[f'{key_prefix}_mean'] = np.mean(data[i])\n",
    "        features[f'{key_prefix}_variance'] = np.var(data[i])\n",
    "        features[f'{key_prefix}_skewness'] = skew(data[i])\n",
    "        features[f'{key_prefix}_kurtosis'] = kurtosis(data[i])\n",
    "        features[f'{key_prefix}_peak_to_peak'] = np.ptp(data[i])\n",
    "\n",
    "        # Fourier Transform (FFT)\n",
    "        fft_values = np.abs(fft(data[i]))\n",
    "        features[f'{key_prefix}_fft_mean'] = np.mean(fft_values)\n",
    "        features[f'{key_prefix}_fft_std'] = np.std(fft_values)\n",
    "        features[f'{key_prefix}_fft_max'] = np.max(fft_values)\n",
    "\n",
    "        # Wavelet Transform (DWT) using Daubechies wavelet (db4)\n",
    "        coeffs = manual_morlet_transform(data[i], scales, fs)\n",
    "        \n",
    "        # Compute wavelet energy\n",
    "        wavelet_energy = sum(np.sum(np.square(c)) for c in coeffs)\n",
    "        features[f'{key_prefix}_wavelet_energy'] = wavelet_energy\n",
    "\n",
    "    # # Wavelet Energy\n",
    "    #     wavelet_energy = sum(np.sum(np.square(c)) for c in coeffs)\n",
    "    #     features[f'{key_prefix}_wavelet_energy'] = wavelet_energy\n",
    "        \n",
    "        wavelet_entropy = 0\n",
    "        for c in coeffs:\n",
    "            c = c[np.isfinite(c)]\n",
    "            c_norm = c / (np.sum(np.abs(c)) + 1e-10)\n",
    "\n",
    "            c_norm = c[c > 0]  # Remove zero or negative values to avoid log errors\n",
    "            if len(c_norm) > 0:\n",
    "                wavelet_entropy += -np.sum(c_norm * np.log2(c_norm))\n",
    "            else:\n",
    "                wavelet_entropy += 0  # If empty, set entropy to 0\n",
    "        features[f'{key_prefix}_wavelet_entropy'] = wavelet_entropy\n",
    "    \n",
    "    # Get the sampling frequency\n",
    "    sfreq = raw.info['sfreq']\n",
    "\n",
    "    # Compute the Nyquist frequency (maximum frequency we can analyze)\n",
    "    nyquist_freq = sfreq / 2\n",
    "\n",
    "    # Ensure fmax does not exceed Nyquist frequency\n",
    "    adjusted_fmax = min(fmax, nyquist_freq)\n",
    "    print(f\"Sampling Frequency: {sfreq} Hz, Nyquist Frequency: {nyquist_freq} Hz, Adjusted fmax: {fmax} Hz\")\n",
    "    # Check if fmin is valid\n",
    "    if fmin >= adjusted_fmax:\n",
    "        raise ValueError(f\"Invalid frequency range: fmin={fmin} is not less than fmax={adjusted_fmax}\")\n",
    "\n",
    "\n",
    "\n",
    "    n_times = raw.n_times  # Get the actual number of time points in the signal\n",
    "    n_fft = min(2048, n_times)  # Ensure n_fft does not exceed signal length\n",
    "\n",
    "\n",
    "    # Frequency-domain features using PSD\n",
    "    psd = raw.compute_psd(method='welch', fmin=fmin, fmax=fmax, n_fft=n_fft)\n",
    "    psd_data = psd.get_data()\n",
    "    freqs = psd.freqs\n",
    "    psd_df = pd.DataFrame(psd_data, columns=freqs, index=channel_names)\n",
    "\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'slow_alpha': (6, 9), 'alpha': (8, 12),\n",
    "             'beta': (12, 30), 'gamma': (30, 50)}\n",
    "\n",
    "    for band, (low, high) in bands.items():\n",
    "        band_power = psd_df.loc[:, (freqs >= low) & (freqs <= high)].mean(axis=1)\n",
    "        for ch in channel_names:\n",
    "            key_prefix = f'{condition}_{ch.lower()}'\n",
    "            features[f'{key_prefix}_{band}_power'] = band_power[ch]\n",
    "\n",
    "    # Frontal Alpha Asymmetry (F3-F4)\n",
    "    if 'F3' in channel_names and 'F4' in channel_names:\n",
    "        features[f'{condition}f3_f4_alpha_asymmetry'] = features[f'{condition}_f4_alpha_power'] - features[f'{condition}_f3_alpha_power']\n",
    "\n",
    "    # Convert features to DataFrame\n",
    "    features_df = pd.DataFrame([features])\n",
    "\n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_combine(eo_file_path, ec_file_path, output_file):\n",
    "    all_features = []\n",
    "    eo=False\n",
    "    ec=False\n",
    "    # Process EO file\n",
    "    try:\n",
    "        raw_eo = mne.io.read_raw_brainvision(eo_file_path)\n",
    "        features_eo = extract_channel_features(raw_eo,\"ec\")\n",
    "        #features_eo['condition'] = 'EO'\n",
    "        all_features.append(features_eo)\n",
    "        eo=True\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # Process EC file\n",
    "    raw_ec = mne.io.read_raw_brainvision(ec_file_path)\n",
    "    features_ec = extract_channel_features(raw_ec,\"eo\")\n",
    "    #features_ec['condition'] = 'EC'\n",
    "    all_features.append(features_ec)\n",
    "    ec=True\n",
    "    # Check if both EO and EC files were processed\n",
    "    \n",
    "    # Combine EO and EC features\n",
    "    if eo and ec:\n",
    "        combined_features = pd.concat(all_features,axis=1)\n",
    "    # print(\"*****************************\",combined_features.shape,\"***********************************\")\n",
    "    # out_path = (out_dir,output_file)\n",
    "    # Save combined features to a single CSV file\n",
    "        combined_features.to_csv(output_file,index=False)\n",
    "        print(f\"Features successfully saved to {output_file}\")\n",
    "    # return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 392)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "raw = pd.read_csv(\"/mnt/data/saikrishna/Team_4/notebooks/old/sub-88000489_ses-1_task-restEC_eeg_1.csv\")\n",
    "raw.head()\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/admincit/Desktop/Team_4/Shap/sub-88000489_ses-1_task-restEC_eeg_1_eeg.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 29)  idle\n",
      "    Range : 0 ... 29999 =      0.000 ...    59.998 secs\n",
      "Ready.\n",
      "Reading 0 ... 29999  =      0.000 ...    59.998 secs...\n",
      "_2.fif Duration: 60.0 sec, Samples: 30000\n"
     ]
    }
   ],
   "source": [
    "# ## DEBUG code\n",
    "# # raw_test = mne.io.read_raw_fif(\"/home/admincit/Desktop/Team_4/split_fif/mdd/sub-88017137_ses-1_task-restEO_eeg_2.fif\", preload=True)\n",
    "# raw_test = mne.io.read_raw_fif(\"/home/admincit/Desktop/Team_4/Shap/sub-88000489_ses-1_task-restEC_eeg_1_eeg.fif\", preload=True)\n",
    "# # print(f\"Samples: {raw_test.n_times}, Duration: {raw_test.n_times / raw_test.info['sfreq']} sec\")\n",
    "# print(f\"_2.fif Duration: {raw_test.n_times / raw_test.info['sfreq']} sec, Samples: {raw_test.n_times}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single file usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ../dataset_s/other/sub-19681349/ses-1/eeg/sub-19681349_ses-1_task-restEO_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Sampling Frequency: 500.0 Hz, Nyquist Frequency: 250.0 Hz, Adjusted fmax: 50 Hz\n",
      "Effective window size : 4.096 (s)\n",
      "Extracting parameters from ../dataset_s/other/sub-19681349/ses-1/eeg/sub-19681349_ses-1_task-restEC_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Sampling Frequency: 500.0 Hz, Nyquist Frequency: 250.0 Hz, Adjusted fmax: 50 Hz\n",
      "Effective window size : 4.096 (s)\n",
      "Features successfully saved to preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "process_and_combine(\"../dataset_s/other/sub-19737061/ses-1/eeg/sub-19737061_ses-1_task-restEO_eeg.vhdr\",\"../dataset_s/other/sub-19737061/ses-1/eeg/sub-19737061_ses-1_task-restEC_eeg.vhdr\",\"preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /home/admincit/Desktop/Team_4/split_fif/mdd/sub-88000489_ses-1_task-restEC_eeg_1_eeg.fif...\n",
      "Error loading file: The header file must be given to read the data, not a file with extension '.fif'.\n"
     ]
    }
   ],
   "source": [
    "process_and_combine(\"/home/admincit/Desktop/Team_4/split_fif/mdd/sub-88000489_ses-1_task-restEC_eeg_1_eeg.fif\",\"/home/admincit/Desktop/Team_4/split_fif/mdd/sub-88000489_ses-1_task-restEO_eeg_1_eeg.fif\",\"preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /mnt/data/saikrishna/Team_4/split_fif_new/mdd2/sub-87999321_ses-1_task-restEC_eeg_1_eeg.fif...\n",
      "Error loading file: The header file must be given to read the data, not a file with extension '.fif'.\n"
     ]
    }
   ],
   "source": [
    "process_and_combine(\"/mnt/data/saikrishna/Team_4/split_fif_new/mdd2/sub-87999321_ses-1_task-restEC_eeg_1_eeg.fif\",\"/mnt/data/saikrishna/Team_4/split_fif_new/mdd2/sub-87999321_ses-1_task-restEO_eeg_1_eeg.fif\",\"preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function To process Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_folder(source_folder, destination_folder):\n",
    "    \"\"\"\n",
    "    Processes all pairs of EO and EC files in the source folder and saves the combined features to CSV files in the destination folder.\n",
    "\n",
    "    Args:\n",
    "        source_folder (str): Path to the folder containing EEG files.\n",
    "        destination_folder (str): Path to the folder where CSV files will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Traverse the folder structure to get all subdirectories\n",
    "    for subdir, _, files in os.walk(source_folder):\n",
    "        print(f\"Processing directory: {subdir}\")\n",
    "        # Collecting EC and EO files\n",
    "        ec_files = sorted([f for f in files if \"restEC_eeg.vhdr\" in f])\n",
    "        eo_files = sorted([f for f in files if \"restEO_eeg.vhdr\" in f])\n",
    "\n",
    "        # Processing the EC and EO file pairs\n",
    "        for ec_file in ec_files:\n",
    "            base_name = ec_file.replace(\"restEC_eeg.vhdr\", \"\")\n",
    "            eo_file = base_name + \"restEO_eeg.vhdr\"\n",
    "\n",
    "            if eo_file in eo_files:\n",
    "                ec_path = os.path.join(subdir, ec_file)\n",
    "                eo_path = os.path.join(subdir, eo_file)\n",
    "                output_path = os.path.join(destination_folder, base_name + \"restcombined_eeg.csv\")\n",
    "                # print(f\"Processing {ec_file} and {eo_file}............................................\")\n",
    "                # process_and_combine(ec_path, eo_path, output_path)\n",
    "                print(f\"Processing {ec_file} and {eo_file}...\")\n",
    "                process_and_combine(ec_path, eo_path, output_path)\n",
    "            else:\n",
    "                print(f\"Warning: No matching EO file found for {ec_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder_from_file(folder_list_file, base_source_folder, destination_folder):\n",
    "    \"\"\"\n",
    "    Processes all pairs of EO and EC files for each subject listed in the folder_list_file.\n",
    "    Saves the combined features to CSV files in the destination folder.\n",
    "\n",
    "    Args:\n",
    "        folder_list_file (str): Path to the text file containing the list of subject IDs.\n",
    "        base_source_folder (str): The base directory where the subject folders are located.\n",
    "        destination_folder (str): Path to the folder where CSV files will be saved.\n",
    "    \"\"\"\n",
    "    # Read the list of subject folders from the text file\n",
    "    with open(folder_list_file, 'r') as f:\n",
    "        subject_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Iterate over each subject\n",
    "    for subject_id in subject_ids:\n",
    "        # Build the path to the subject's EEG directory\n",
    "        subject_folder = os.path.join(base_source_folder, subject_id, 'ses-1', 'eeg')\n",
    "\n",
    "        if not os.path.exists(subject_folder):\n",
    "            print(f\"Warning: EEG folder not found for {subject_id}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing subject: {subject_id} in directory {subject_folder}\")\n",
    "\n",
    "        # Get the list of files in the subject's EEG folder\n",
    "        files = os.listdir(subject_folder)\n",
    "\n",
    "        # Collecting EC and EO files\n",
    "        ec_files = sorted([f for f in files if \"restEC_eeg.vhdr\" in f])\n",
    "        eo_files = sorted([f for f in files if \"restEO_eeg.vhdr\" in f])\n",
    "\n",
    "        # Processing the EC and EO file pairs\n",
    "        for ec_file in ec_files:\n",
    "            base_name = ec_file.replace(\"restEC_eeg.vhdr\", \"\")\n",
    "            eo_file = base_name + \"restEO_eeg.vhdr\"\n",
    "\n",
    "            if eo_file in eo_files:\n",
    "                ec_path = os.path.join(subject_folder, ec_file)\n",
    "                eo_path = os.path.join(subject_folder, eo_file)\n",
    "                output_path = os.path.join(destination_folder, base_name + \"restcombined_eeg.csv\")\n",
    "\n",
    "                print(f\"Processing {ec_file} and {eo_file}...\")\n",
    "                process_and_combine(ec_path, eo_path, output_path)\n",
    "            else:\n",
    "                print(f\"Warning: No matching EO file found for {ec_file} in subject {subject_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"/home/admincit/Desktop/Team_4//healthy\"\n",
    "destination_folder = \"/home/admincit/Desktop/Team_4/split_fif/healthy_csv\"\n",
    "process_folder(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: /mnt/data/saikrishna/Team_4/split_fif_new/mdd2\n"
     ]
    }
   ],
   "source": [
    "source_folder = \"/mnt/data/saikrishna/Team_4/split_fif_new/mdd2\"\n",
    "destination_folder = \"/mnt/data/saikrishna/Team_4/preprocessed_data_new/mdd2\"\n",
    "process_folder(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = \"../dataset_s/other/o.txt\"\n",
    "source_folder = \"../dataset_s/other\"\n",
    "destination_folder = \"../split_fif/other_csv\"\n",
    "process_folder_from_file(txt_file, source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"../dataset_s/other\"\n",
    "destination_folder = \"../split_fif/other_csv\"\n",
    "process_folder(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
